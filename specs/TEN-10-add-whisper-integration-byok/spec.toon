plan:
  title: ten-10-whisper-integration-byok
  goal: Enable microphone capture in the document editor that transcribes audio with OpenAI Whisper using a user-provided API key and selected input device stored in local Tauri config.
  steps[5]:
    - title: add-openai-settings-storage-and-ui
      goal: Add OpenAI API key and preferred microphone settings in the existing settings modal using the current Tauri config pattern.
      context: "Project root is `/Users/nicolas/Code/polvera/tentacle-app`. Frontend app is in `frontend/` (Next.js 16, React 19, TypeScript, Tailwind). Tauri config commands already exist in `frontend/src-tauri/src/lib.rs`: `get_config(key) -> Option<String>` and `set_config(key, value) -> ()`. Existing settings storage pattern is `frontend/lib/settings/documents-folder.ts`, which uses `invoke` from `@tauri-apps/api/core`, guards server usage with `typeof window === 'undefined'`, and exports async get/set helpers. Existing modal UI is `frontend/components/settings/settings-modal.tsx`; it currently renders only a Documents folder section and button row using rounded-full controls and violet focus styles. This step must create `frontend/lib/settings/openai-config.ts` and update `frontend/components/settings/settings-modal.tsx`; those exports will be consumed by step 3 voice capture."
      instructions: "Create `frontend/lib/settings/openai-config.ts` and export: `CONFIG_KEY_OPENAI_API_KEY = 'openai_api_key'`, `CONFIG_KEY_INPUT_DEVICE = 'input_device'`, `getOpenAIApiKey(): Promise<string | null>`, `setOpenAIApiKey(apiKey: string): Promise<void>`, `getInputDevice(): Promise<string | null>`, and `setInputDevice(deviceId: string): Promise<void>`. Implement them with `invoke('get_config'|'set_config')`, trim API key values on read/write, and follow the same server-side guard behavior as `documents-folder.ts`. Modify `frontend/components/settings/settings-modal.tsx` to import these helpers, add state for `apiKey`, `inputDevice`, `availableDevices` (array of `{ deviceId: string; label: string }`), and `isSavingApiKey`, and in the existing `open` effect load folder, API key, saved input device, and available microphones via `navigator.mediaDevices.enumerateDevices()` filtered to `kind === 'audioinput'`. Add an OpenAI API key section with password input and helper text `Required for voice transcription. Your key is stored locally.`; save on input blur via `setOpenAIApiKey`. Add an Input Device section with a select whose first option is `Default` with empty value and whose change handler persists via `setInputDevice`. Update modal description text to `Configure your documents folder, voice input, and API keys.`. Keep documents-folder choose flow and existing modal close interactions unchanged."
      verification: "Run `cd frontend && npx tsc --noEmit` and confirm zero type errors. Then open settings UI and verify it shows Documents folder, OpenAI API Key, and Input Device sections; API key and selected device persist after closing and reopening the modal."
    - title: allow-openai-network-calls-in-tauri-csp
      goal: Permit requests from the desktop webview to the OpenAI transcription endpoint.
      context: "Tauri app config is `frontend/src-tauri/tauri.conf.json`. Current CSP under `app.security.csp` has `connect-src 'self'`, which blocks fetch calls to external APIs. The Whisper BYOK implementation in step 3 will call `https://api.openai.com/v1/audio/transcriptions` directly from the frontend. Existing style keeps a single CSP string with semicolon-delimited directives."
      instructions: "Modify only `frontend/src-tauri/tauri.conf.json` and update the CSP string so `connect-src` includes both `'self'` and `https://api.openai.com`. Keep all other directives (`default-src`, `style-src`, `font-src`, `img-src`, `script-src`) unchanged. Do not modify window sizing, bundle settings, or identifiers."
      verification: "Run `cd frontend && cargo check --manifest-path src-tauri/Cargo.toml` to ensure Tauri config remains valid for build tooling, then confirm by code review that CSP contains `connect-src 'self' https://api.openai.com`."
    - title: create-voice-capture-component
      goal: Add a reusable client component that records microphone audio and transcribes it with OpenAI Whisper.
      context: "This step depends on step 1 output: `frontend/lib/settings/openai-config.ts` exports `getOpenAIApiKey()` and `getInputDevice()`. Existing toast pattern is `frontend/components/ui/error-toast.tsx` exporting `ErrorToast` with props `{ message: string; onDismiss: () => void; duration?: number }`. No voice capture component currently exists. Frontend dependencies already include React and TypeScript; do not add new packages. Component should be mobile-friendly and match existing 44x44 minimum touch targets and violet visual language used in `frontend/components/documents/editor-toolbar.tsx`."
      instructions: "Create `frontend/components/voice-capture.tsx` as a `'use client'` component exporting `interface VoiceCaptureProps { onTranscription: (text: string) => void; onError?: (message: string) => void }` and `export function VoiceCapture(props: VoiceCaptureProps)`. Implement recording with `navigator.mediaDevices.getUserMedia` + `MediaRecorder`: use saved input device from `getInputDevice()` as `deviceId: { exact: savedId }` when non-empty, otherwise use default audio input. Track `isRecording`, `isTranscribing`, `recordingDuration`, and `errorMessage` state; show timer while recording. On stop, convert chunks to a Blob/File and call `fetch('https://api.openai.com/v1/audio/transcriptions', { method: 'POST', headers: { Authorization: 'Bearer <key>' }, body: FormData(model=whisper-1,file=<audio>) })`. Read `text` from JSON response, trim it, and call `onTranscription(text)` when non-empty. If no API key exists, fail immediately with `OpenAI API key not configured. Set it in Settings.`. Handle microphone permission failures and network/API failures by setting `errorMessage` and calling optional `onError`. Render one round icon button that toggles recording/stopping, a compact recording/transcribing status text, and `ErrorToast` when `errorMessage` is set. Ensure media tracks and timers are cleaned up on stop and unmount."
      verification: "Run `cd frontend && npx tsc --noEmit`. In app runtime, click the voice button with no API key and verify the expected error toast; with a valid key verify recording starts, stop triggers transcription request, and returned text reaches `onTranscription`."
    - title: integrate-voice-capture-into-editor-and-empty-state
      goal: Wire transcription insertion into the document editor and remove the duplicate Voice empty-state card.
      context: "`frontend/components/documents/document-editor.tsx` currently exports `DocumentEditor({ initialContent, onContentChange })` and renders `<EditorToolbar editor={editor} />` above `<EditorContent editor={editor} />`; it already has access to the `editor` instance and uses `editor.chain().focus().*` command style. `frontend/components/documents/input-source-cards.tsx` currently defines `sources` with Voice, Link, File and renders a `sm:grid-cols-3` layout. `frontend/app/app/documents/page.tsx` already uses `DocumentEditor` and conditionally renders `InputSourceCards` when body is empty; no API signature changes are desired for this page."
      instructions: "Modify `frontend/components/documents/document-editor.tsx` to import `VoiceCapture` from `@/components/voice-capture` and render it in the toolbar row. Keep existing `DocumentEditorProps` unchanged. Replace the current top area with a flex container that includes `<EditorToolbar editor={editor} />` and `<VoiceCapture onTranscription={(text) => editor?.chain().focus().insertContent(text).run()} />`, then render `<EditorContent editor={editor} />` below. Do not add ref forwarding or alter parent usage. Modify `frontend/components/documents/input-source-cards.tsx` by removing the Voice source entry from `sources` and changing the grid class from `sm:grid-cols-3` to `sm:grid-cols-2`; keep Link and File cards unchanged. Do not modify `frontend/app/app/documents/page.tsx` except if imports become unused."
      verification: "Run `cd frontend && npx tsc --noEmit` and `cd frontend && npm run lint`. Verify by code review that `DocumentEditor` inserts transcribed text via `insertContent`, and `InputSourceCards` no longer contains a Voice card."
    - title: run-quality-gates-and-feature-smoke-test
      goal: Validate the full BYOK Whisper flow and ensure the codebase passes standard checks.
      context: "After steps 1-4, changed files are `frontend/lib/settings/openai-config.ts`, `frontend/components/settings/settings-modal.tsx`, `frontend/src-tauri/tauri.conf.json`, `frontend/components/voice-capture.tsx`, `frontend/components/documents/document-editor.tsx`, and `frontend/components/documents/input-source-cards.tsx`. Standard frontend scripts are in `frontend/package.json`: `lint` (eslint), `build` (next build --webpack)."
      instructions: "Run `cd frontend && npx tsc --noEmit`, `cd frontend && npm run lint`, and `cd frontend && npm run build`; fix only issues introduced by this feature. Then perform a manual smoke test in the running app: set API key and microphone in Settings, open a document, start recording from editor toolbar, stop recording, confirm transcribed text appears in the editor, and confirm empty-state cards show only Link and File. Do not refactor unrelated modules."
      verification: "All three commands exit with code 0, and manual smoke test confirms transcription insertion plus updated empty state behavior without regressions in settings folder selection."
  acceptance_criteria[7]:
    - title: openai-settings-are-persisted-locally
      requirement: "`frontend/lib/settings/openai-config.ts` exists and uses `invoke('get_config')` and `invoke('set_config')` with keys `openai_api_key` and `input_device`; reopening settings shows previously saved values."
    - title: settings-modal-includes-voice-configuration-sections
      requirement: "`frontend/components/settings/settings-modal.tsx` renders OpenAI API Key and Input Device sections in addition to Documents folder, and the modal description text mentions documents folder, voice input, and API keys."
    - title: tauri-csp-allows-openai-endpoint
      requirement: "`frontend/src-tauri/tauri.conf.json` CSP `connect-src` includes `https://api.openai.com` alongside `'self'`."
    - title: voice-capture-component-handles-recording-and-transcription
      requirement: "`frontend/components/voice-capture.tsx` uses `MediaRecorder`, obtains API key via `getOpenAIApiKey`, posts audio to `https://api.openai.com/v1/audio/transcriptions` with model `whisper-1`, and calls `onTranscription` with non-empty text."
    - title: missing-api-key-shows-clear-error
      requirement: "Without a configured key, clicking the voice button surfaces the message `OpenAI API key not configured. Set it in Settings.` and does not attempt network transcription."
    - title: editor-and-empty-state-are-wired-correctly
      requirement: "`frontend/components/documents/document-editor.tsx` renders `VoiceCapture` next to `EditorToolbar` and inserts transcribed text with `editor.chain().focus().insertContent(text).run()`, and `frontend/components/documents/input-source-cards.tsx` contains only Link and File cards."
    - title: quality-gates-pass
      requirement: "`cd frontend && npx tsc --noEmit && npm run lint && npm run build` completes with no errors."
